<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>shellfly&#39;s blog</title>
    <link>https://shellfly.org/</link>
    <description>Recent content on shellfly&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 22 Feb 2020 15:14:45 +0800</lastBuildDate>
    
	<atom:link href="https://shellfly.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>B树和数据库索引</title>
      <link>https://shellfly.org/posts/b-tree-and-database-index/</link>
      <pubDate>Sat, 22 Feb 2020 15:14:45 +0800</pubDate>
      
      <guid>https://shellfly.org/posts/b-tree-and-database-index/</guid>
      <description>很早就知道数据库索引是用B树实现的，但其实并不理解它的工作细节，也不知道树的节点里到底存了什么。最近重读了《算法 第4版》，最后一章作为扩展有一节提到了B树的实现，看了之后理解了一点，然后又在youtube上找到了一个讲解的非常好的教程，看完准备写下这篇文章帮忙自己理解，如果你也对这个话题感兴趣，非常推荐也去看一看(链接会放在文章结尾)。
文章会分为四个部分
 磁盘访问的代价 索引结构 B树 MySQL和PostgreSQL里面索引实现的区别  磁盘访问代价 和内存相比，访问磁盘的延时要高得多。假设没有索引，数据直接存在磁盘上（通常数据库会把一张表存在一个文件里面），当我们想要访问一条或者某些记录的时候，就需要从磁盘读取整个文件，因为我们不知道具体数据的磁盘地址，你可以想象如果我们只需要更新一条记录的代价有多大。尽管现在SSD已经很普遍，它也需要0.25到1ms的延时，最快的读取速度也就500MB/s到1GB/s。
所以我们需要一种机制来获取我们需要访问数据的地址，它可能是机械磁盘的一个扇区，或者是SSD的一个页，索引就是提供这种功能的机制。
索引结构 如果你是一个开发者，你肯定已经对索引有了一个大致的概念。数据库索引就像是书的目录一样，你可以通过它知道你感兴趣的内容在哪一页。在计算机的术语里，数据也是按照一页一页存储的。
索引是按照树的结构构造的，从最简单的二叉搜索树开始看，二叉搜索树的每个节点最多有两个子节点，并且每个节点里的键大于或等于它的左子节点，小于它的右子节点。在理想情况下，访问任一节点需要的最大时间都是对数级别的。
如果我们想要用树的结构来存储索引，有两点需要注意。第一个是树的高度，我们可以把二叉树变成多叉树，来进一步降低树的高度。第二个是树的平衡，一个M叉树，需要保证每一个节点（根节点除外）至少包含M/2个键，并且所有叶子节点都在同一层级上。
B树 B树就是实现了上面两种特性的一种树结构。索引自己本身作为一种数据，也是需要存到磁盘上的，当然也是分成很多页。PostgreSQL使用8KB作为一页的大小，MySQL使用16KB。根据服务器磁盘配置的不同，可能需要一到两次I/O操作来读取一页的数据。为了最小化磁盘访问次数，数据库索引中树的每一个节点就是一页的大小。
B树还有一种变体叫做B+树。它们的不同是，B+树的内部节点不存储键值对，而只有键。这样在一页大小的限制下就能存储更多的键。所有的内部节点都会在叶子节点有一份拷贝，叶子结点里存储键值对，并且会用链表关联起来，方便遍历。
MySQL和PostgreSQL都使用了这种结构，不过PostgrsSQL还是称它B树，而不是B+树，因为PostgreSQL里面的索引里的值永远是指针，而不是像InnoDB那样，会把表的数据直接存在索引（聚簇索引）里。
MySQL和PostgreSQL里面索引实现的区别 MySQL里有一种特殊的索引叫做聚簇索引（clustered index），它只用在主键上，表的内容是按照主键的值的顺序组织存在磁盘上的。其他二级索引里的键值对里的值是主键。
在使用聚簇索引的情况下，用主键去访问表里的数据是非常快的，因为只有一次I/O操作。而且这种场景很常见，比如按照自增的ID排序，或者用外键join其他表的时候。
缺点就是如果使用的是二级索引来访问数据，就需要遍历两次树，一次是二级索引得到主键，然后遍历聚簇索引得真正的表数据。
PostgreSQL里的索引和表是完全分开的，表的数据存储在叫做heap的结构里。索引的值就是表的磁盘位置，用主键访问还是其他索引访问并没有什么区别。
另外一个使用聚簇索引的好处就是，如果数据库有频繁更新的操作，为了支持MVCC，表里会同时存在很多不同版本的数据，如果没有聚簇索引，而是索引都直接指向磁盘位置，那么每次更新都需要对所有的索引进行更新或者新建新的索引。尽管PostgreSQL里面有使用HOT这种技术来避免这种情况的发生，不过它限制在新的数据也需要在同一个页里面，并且不能更新索引的列。这也是Uber从PostgreSQL切换到MySQL的主要原因。
Reference
https://github.com/kevin-wayne/algs4 https://www.youtube.com/watch?v=aZjYr87r1b8 http://codecapsule.com/2014/02/12/coding-for-ssds-part-2-architecture-of-an-ssd-and-benchmarking/ https://use-the-index-luke.com/sql/anatomy https://www.postgresql.org/docs/12/storage-page-layout.html https://dev.mysql.com/doc/refman/8.0/en/innodb-physical-structure.html https://en.wikipedia.org/wiki/Talk%3AB%2B_tree#PostgreSQL&#39;s_use_of_B+_trees https://github.com/postgres/postgres/blob/master/src/backend/access/heap/README.HOT https://eng.uber.com/mysql-migration/ </description>
    </item>
    
    <item>
      <title>排序算法</title>
      <link>https://shellfly.org/posts/sorting-algorithms/</link>
      <pubDate>Sun, 09 Feb 2020 21:20:50 +0800</pubDate>
      
      <guid>https://shellfly.org/posts/sorting-algorithms/</guid>
      <description>记得很早之前的一个同事新人，跟我开始了这样一次对话：
“你知道Python里面的排序用的是什么算法吗？”
“肯定是快排。“，我说。
”不对，是叫Timsort，是一个叫Tim的人开发的“
“就算现在不是快排，最开始也肯定是快排”。
我加强语气来掩饰自己对这个问题其实并不了解，直到很久以后我才知道，Timsort其实是的归并排序和插入排序的混合。
每个（只）学过一点算法的人，大概都会有快排是最好的排序算法的印象。最近重读《编程珠玑》，在第一章里，作者提到了最开始打算用归并排序去解决一个大文件的排序问题，深入分析问题后，发现可以利用bitmap，在O(n)的时间里解决那个具体的排序问题的故事。我的第一反应是为什么他首先就想到归并排序而不是其他算法呢，借此机会重新复习了一下各种排序算法的特性，以及他们的优劣之处。
考虑一个简单的场景，我们需要把一副扑克牌，从右边移动到左边，同时按照从小到大的顺序排好。最直观的做法就是，按照顺序一张一张移动，每次移动到左边时，我们都会找到合适的位置插入进去，这个方法也就是插入排序的思想。 从它的描述，我们就知道他实现起来非常简单，而且当元素的数量较小或者大部分元素有序的时候，这其实是一个非常有效的算法，不过它在最坏的情况下也是O(n^2)的时间。
和插入排序类似的一个算法就是选择排序，过程不再是直接选择下一个、插入已经排序的元素里面，而是每次都直接从未排序的里面直接选出合适的来移动，所以选择排序的执行时间完全和数据的输入无关，它永远是N^2的，唯一的优势是数据交换的次数最少，不过这个优势好像也没什么用。
插入排序和选择排序都很好理解，也很容易实现，但是大部分时间他们的效率都不是很高，所以还需要一些稍微高级一点的排序算法，快排（Quicksort）就是其中一种。叫快排是因为在同类基于比较的算法中，它确实很快。它的思想是，每次选择一个切分元素（Pivot），把元素分成小于和大于的两份，然后再递归的按同样的方式应用到切分后的两部分。快速排序平均时间是O(NlogN)，虽然在最坏的情况下也需要O(n^2)的时间，不过这种情况很少出现，而且可以通过先打乱数组来避免。快速排序的限制在于内存访问，需要数据可以完全放在内存中，并且可以随机访问。如果数据量太大，或者是像链表这样无法随机访问的数据结构就不适合用快排。
归并排序（Mergesort）和快排一样，是一个分而治之（divide-and-conquer ）的算法。它也是递归的处理数组的两部分，不过排序的过程不在切分，而是在把小的数组归并回大的数组的时候，虽然平均起来它比快排慢一点，但是它可以保证在最坏的情况下也是O(NlogN)的时间，而且不需要随机访问数据，非常适合用来排序存储在外部的数据，比如磁盘或者网络，当然链表更不在话下。不过要实现它需要O（n）的额外空间，这在一些内存比较紧张的嵌入式系统或者移动设备中会比较不适合。
还有一种比较常见的排序就是堆排序（Heapsort），这个堆和内存的那个堆没什么关系，这里是一种数据结构，通常都是二叉堆，也就是一个二叉树，之所以叫堆是因为元素在插入和删除的过程中会保证每个节点元素都不大于父节点（MaxHeap），或者都不小于父节点（MinHeap），所以根节点永远是最大或者最小的那个。因为维护一个堆的数据结构的开销很小，只需要LogN次的操作，所以可以利用堆的这个属性来实现排序。堆排序实现起来也比较简单，能够保证最坏的时间是O（NlogN）而且不需要額外的存储空间，只不过它的比较很少在相邻的元素之间，所以无法有效的利用缓存。
再说回最开始提到的Timsort，它其实是混合了归并排序和插入排序的算法，先把数组分成不同的部分，Timsort里面叫做Run，用插入排序，然后再用归并排序里面的merge方法，把这些Run合并成更大的有序数组。虽然只是基于归并和插入排序，Timsort在实现的过程中做了很多优化，比如用基于二分查找的插入排序，避免归并大小相差太大的子数组，效果也相当不错，根据Wikipedia来看，Timsort现在不仅用在Python中，Java ，Android和Switft也都在用。</description>
    </item>
    
    <item>
      <title>为什么Python有一个GIL</title>
      <link>https://shellfly.org/posts/why-does-python-have-a-gil/</link>
      <pubDate>Mon, 19 Mar 2018 17:14:00 +0800</pubDate>
      
      <guid>https://shellfly.org/posts/why-does-python-have-a-gil/</guid>
      <description>GIL GIL是Global Interpreter Lock的缩写，也就是全局的解释器锁。CPython用GIL来保证同一时间只有一个线程在执行Python代码。所以即使多个线程被操作系统分配到CPU不同的核里，最终的效果还是线性执行，没法利用多核的优势。这也就导致了多线程程序的执行效率大大降低。
所以Python里到底为什么一定要有一个GIL呢？
Python官方文档中关于GIL有一段简要的说明：
 Python interpreter is not fully thread-safe. In order to support multi-threaded Python programs, there’s a global lock, called the global interpreter lock or GIL.
 简单翻译一下就是：因为Python解释器（CPython）自身不是完全线程安全的，所以为了支持多线程的Python程序，需要有一个全局解释器锁，也就是GIL。
线程安全（Thread Safe） 如果用C或者Java写过多线程程序，就会知道访问共享资源的时候都是需要加锁的。CPython顾名思义，就是用C实现的Python解释器，当启用多线程的时候，为了保证代码的正确性，就需要锁，而GIL就是一把超级大锁，每个线程开始执行之前都需要先获得GIL，其他没有获得GIL的线程保持在等待状态，而像JVM中则采用细粒度(fine-grained)的锁来保证线程安全。
通常有两种操作会导致线程释放GIL，一种是协作式的（cooperative），在执行I/O操作之前，线程会主动释放GIL。另一种是抢占式的（preemptive），线程执行一定时间后会被迫释放GIL。
但是并不是有了GIL后，就不需要再关心线程安全了。GIL只能保证Python的内部数据结构同一时间只有一个线程可以访问，其实是保证了单独的操作是线程安全的，不需要额外的保护措施。但是如果有特定顺序的连续调用，还是需要用户显式的加锁来控制程序的正确性，也就是《深入理解Java虚拟机》中描述的相对线程安全。
GIL的优点 使用GIL最重要的原因就是：它可以让单线程程序的速度非常快，不需要考虑锁的释放和获取，和用细粒度的锁来保证解释器状态相比，省了很多不必要的操作。
在集成C库时，也不需要担心线程安全，如果不是线程安全的，只需要在调用的时候先获取GIL即可。
PS: 人脑和python解释器一样也有个GIL，一次只能处理一件事，通过context switch来模拟多线程运行。所以学过Python后一定要记得一件事，开车时不要看手机。</description>
    </item>
    
    <item>
      <title>2018</title>
      <link>https://shellfly.org/posts/my-first-post/</link>
      <pubDate>Sun, 28 Jan 2018 22:20:10 +0800</pubDate>
      
      <guid>https://shellfly.org/posts/my-first-post/</guid>
      <description>2018 希望从现在开始可以创造一些东西</description>
    </item>
    
  </channel>
</rss>